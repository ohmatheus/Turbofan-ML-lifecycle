{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Multiple Scenarios:",
   "id": "e4c21a0ab30f56d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scenario 1 (Competition): One model for all subsets (001, 002, 003, 004)\n",
    "\n",
    "→ Merge all 4, then split, then scale"
   ],
   "id": "f29b3d9d197cd0b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scenario 2 (Competition): Separate model per subset\n",
    "\n",
    "→ 4 separate splits + 4 separate scalers etc"
   ],
   "id": "fa6a159584f1bb5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Scenario 3 (Drift simulation, this project): One model, retained when drift detected\n",
    "\n",
    "-> Train first on 001 train (split, scale), then when drift detected, 001 + 002, then if drift.. etc\n",
    "\n",
    "This is the strategy we will go for. So we will only use this notebook as a sandbox, to write functions and automate data loading and preprocessing."
   ],
   "id": "430ccb47832b250e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "But I keep the 2 previous scenario in mind in case I want to do a 'late submission' for the competition.",
   "id": "6b0c8ffd1f5bf013"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "_____",
   "id": "1c3d66df64a14b8a"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-26T05:39:56.911573Z",
     "start_time": "2025-10-26T05:39:56.908285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.utils.config import config\n",
    "import warnings\n",
    "np.random.seed(34)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ],
   "id": "7baba2d5234739f8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load from raw - prepare",
   "id": "67e004d26f36e408"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T05:39:32.128920Z",
     "start_time": "2025-10-26T05:39:32.127659Z"
    }
   },
   "cell_type": "code",
   "source": "subsets = ['001', '002', '003', '004']",
   "id": "ea3876f96ee9c3e4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T05:39:32.132077Z",
     "start_time": "2025-10-26T05:39:32.130857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index_names = ['unit_number', 'time_cycles']\n",
    "setting_names = ['setting_1', 'setting_2', 'setting_3']\n",
    "sensor_names = ['s_{}'.format(i+1) for i in range(0,21)]\n",
    "col_names = index_names + setting_names + sensor_names"
   ],
   "id": "3a824e4dd3c439c7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T05:39:32.342039Z",
     "start_time": "2025-10-26T05:39:32.133894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "raw_data_path = config.RAW_DATA_PATH / 'CMaps/'\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for fd_num in subsets:\n",
    "    datasets[fd_num] = {\n",
    "        'train': pd.read_csv(raw_data_path / f'train_FD{fd_num}.txt', sep='\\s+', header=None, index_col=False, names=col_names),\n",
    "        'test': pd.read_csv(raw_data_path / f'test_FD{fd_num}.txt', sep='\\s+', header=None, index_col=False, names=col_names),\n",
    "        'rul': pd.read_csv(raw_data_path / f'RUL_FD{fd_num}.txt', sep='\\s+', header=None, index_col=False, names=['RUL'])\n",
    "    }"
   ],
   "id": "32f38dfec4c6c5bf",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T05:39:32.347480Z",
     "start_time": "2025-10-26T05:39:32.345800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for fd_num in subsets:\n",
    "    train = datasets[fd_num]['train']\n",
    "    valid = datasets[fd_num]['test']\n",
    "    print(f'FD{fd_num}:')\n",
    "    print(f'  Train shape: {train.shape}')\n",
    "    print(f'  Test shape: {valid.shape}')\n",
    "    print(f'  Test %: {len(valid)/(len(valid)+len(train))*100.0:.3f}')\n",
    "    print()"
   ],
   "id": "485ffae5e06e5f6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD001:\n",
      "  Train shape: (20631, 26)\n",
      "  Test shape: (13096, 26)\n",
      "  Test %: 38.829\n",
      "\n",
      "FD002:\n",
      "  Train shape: (53759, 26)\n",
      "  Test shape: (33991, 26)\n",
      "  Test %: 38.736\n",
      "\n",
      "FD003:\n",
      "  Train shape: (24720, 26)\n",
      "  Test shape: (16596, 26)\n",
      "  Test %: 40.168\n",
      "\n",
      "FD004:\n",
      "  Train shape: (61249, 26)\n",
      "  Test shape: (41214, 26)\n",
      "  Test %: 40.223\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T06:19:13.734972Z",
     "start_time": "2025-10-26T06:19:13.731062Z"
    }
   },
   "cell_type": "code",
   "source": "datasets['001']['rul']",
   "id": "cac4f9196bb811fc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    RUL\n",
       "0   112\n",
       "1    98\n",
       "2    69\n",
       "3    82\n",
       "4    91\n",
       "..  ...\n",
       "95  137\n",
       "96   82\n",
       "97   59\n",
       "98  117\n",
       "99   20\n",
       "\n",
       "[100 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T06:20:24.627813Z",
     "start_time": "2025-10-26T06:20:24.596010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_RUL_column(df, ref_rul=None):\n",
    "    train_grouped_by_unit = df.groupby(by='unit_number')\n",
    "    max_time_cycles = train_grouped_by_unit['time_cycles'].max()\n",
    "    merged = df.merge(max_time_cycles.to_frame(name='max_time_cycle'), left_on='unit_number', right_index=True)\n",
    "\n",
    "    if ref_rul is not None:\n",
    "        # For test data with reference RUL\n",
    "        # Extract values from DataFrame (first column)\n",
    "        ref_rul_values = ref_rul.iloc[:, 0]\n",
    "\n",
    "        unique_units = df['unit_number'].nunique()\n",
    "        assert len(ref_rul_values) == unique_units, f\"RUL count ({len(ref_rul_values)}) ≠ unique units ({unique_units})\"\n",
    "\n",
    "        unit_numbers = sorted(df['unit_number'].unique())\n",
    "        rul_mapping = dict(zip(unit_numbers, ref_rul_values))\n",
    "        merged['ref_rul'] = merged['unit_number'].map(rul_mapping)\n",
    "        merged[\"RUL\"] = merged['ref_rul'] + (merged[\"max_time_cycle\"] - merged['time_cycles'])\n",
    "        merged = merged.drop([\"max_time_cycle\", \"ref_rul\"], axis=1)\n",
    "    else:\n",
    "        # For training data\n",
    "        merged[\"RUL\"] = merged[\"max_time_cycle\"] - merged['time_cycles']\n",
    "        merged = merged.drop(\"max_time_cycle\", axis=1)\n",
    "\n",
    "    return merged\n",
    "\n",
    "# Apply to all datasets\n",
    "for fd_num in subsets:\n",
    "    datasets[fd_num]['train'] = add_RUL_column(datasets[fd_num]['train'])\n",
    "    datasets[fd_num]['test'] = add_RUL_column(datasets[fd_num]['test'], datasets[fd_num]['rul'])"
   ],
   "id": "83c5212ce671bf0e",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T06:20:26.881705Z",
     "start_time": "2025-10-26T06:20:26.878542Z"
    }
   },
   "cell_type": "code",
   "source": "datasets['001']['train'].columns",
   "id": "4f9e43356ddd5be0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit_number', 'time_cycles', 'setting_1', 'setting_2', 'setting_3',\n",
       "       's_1', 's_2', 's_3', 's_4', 's_5', 's_6', 's_7', 's_8', 's_9', 's_10',\n",
       "       's_11', 's_12', 's_13', 's_14', 's_15', 's_16', 's_17', 's_18', 's_19',\n",
       "       's_20', 's_21', 'RUL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T06:21:36.204517Z",
     "start_time": "2025-10-26T06:21:36.202506Z"
    }
   },
   "cell_type": "code",
   "source": "datasets['001']['test'].columns",
   "id": "307135817f8ced82",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit_number', 'time_cycles', 'setting_1', 'setting_2', 'setting_3',\n",
       "       's_1', 's_2', 's_3', 's_4', 's_5', 's_6', 's_7', 's_8', 's_9', 's_10',\n",
       "       's_11', 's_12', 's_13', 's_14', 's_15', 's_16', 's_17', 's_18', 's_19',\n",
       "       's_20', 's_21', 'RUL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Merge all, add columns for subset source, and save as 1 prepared dataframe",
   "id": "2dbb83f22d5dcbe6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T05:40:43.668462Z",
     "start_time": "2025-10-26T05:40:42.293787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for fd_num in subsets:\n",
    "    train_subset = datasets[fd_num]['train'].copy()\n",
    "    train_subset['subset'] = fd_num\n",
    "    train_data.append(train_subset)\n",
    "\n",
    "    test_subset = datasets[fd_num]['test'].copy()\n",
    "    test_subset['subset'] = fd_num\n",
    "    test_data.append(test_subset)\n",
    "\n",
    "# Concatenate all train and test dataframes\n",
    "train_df = pd.concat(train_data, ignore_index=True)\n",
    "test_df = pd.concat(test_data, ignore_index=True)\n",
    "\n",
    "processed_dir = config.PREPARED_DATA_PATH\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "train_df.to_csv(processed_dir / 'train-all-prepared.csv', index=False)\n",
    "test_df.to_csv(processed_dir / 'test-all-prepared.csv', index=False)\n",
    "\n",
    "print(f\"Train dataset shape: {train_df.shape}\")\n",
    "print(f\"Test dataset shape: {test_df.shape}\")\n",
    "print(\"CSV files saved successfully!\")"
   ],
   "id": "c7eb5e219ab27bf1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (160359, 28)\n",
      "Test dataset shape: (104897, 27)\n",
      "CSV files saved successfully!\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "_________________",
   "id": "77c1632f481038e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T05:39:32.484701Z",
     "start_time": "2025-10-26T04:04:41.290208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# #we do not want to scale the index and the settings\n",
    "# drop_labels = index_names+setting_names\n",
    "#\n",
    "# #for fd_num in subsets:\n",
    "# X_train=datasets['001']['train'].drop(columns=drop_labels).copy()\n",
    "# X_train, X_test, y_train, y_test=train_test_split(X_train,X_train['RUL'], test_size=0.3, random_state=42)\n",
    "# scaler = MinMaxScaler()\n",
    "# #Droping the target variable\n",
    "# X_train.drop(columns=['RUL'], inplace=True)\n",
    "# X_test.drop(columns=['RUL'], inplace=True)\n",
    "# #Scaling X_train and X_test\n",
    "# X_train_s=scaler.fit_transform(X_train)\n",
    "# X_test_s=scaler.transform(X_test)\n",
    "# #Conserve only the last occurence of each unit to match the length of y_valid\n",
    "# X_valid = datasets['001']['test'].groupby('unit_number').last().reset_index().drop(columns=drop_labels)\n",
    "# #scaling X_valid\n",
    "# X_valid_s=scaler.transform(X_valid)\n"
   ],
   "id": "32bfae0dcf83b977",
   "outputs": [],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
